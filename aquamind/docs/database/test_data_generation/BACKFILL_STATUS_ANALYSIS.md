# Test Data Generation - Backfill Status Analysis

**Analysis Date:** 2025-10-23  
**Question:** Do test scripts handle harvest and feeding summaries without backfilling?

---

## üéØ **Executive Summary**

### **Answer: MOSTLY YES, but with caveats**

‚úÖ **Harvest Events:** Working perfectly in test scripts (no backfill needed)  
‚úÖ **Feeding Summaries:** Auto-generated via signals (working as designed)  
‚ö†Ô∏è **Coverage:** Sparse but functional (by design - 30-day rolling window)

---

## üìä **Current Status**

### **1. Harvest Events** ‚úÖ WORKING

```
Status: ‚úÖ PROPERLY GENERATED BY TEST SCRIPTS
```

**Evidence:**
```
Harvest Events Created: 380 events
Harvest Lots Created:   1,900 lots (5 grades per event)
Batches Harvested:      38 out of 54 batches (70%)
Batch Distribution:     44 Adult, 10 in earlier stages
```

**Test Script Implementation:**
```python
# Location: scripts/data_generation/03_event_engine_core.py
# Lines: 599-688

def harvest_batch(self):
    """Harvest the batch if it's in Adult stage and ready"""
    # Checks:
    # 1. Batch is in Adult stage
    # 2. Average weight > 4kg (4000g)
    
    # Creates:
    # - HarvestEvent for each container
    # - HarvestLot for each grade (SUPERIOR, A, B, C, REJECT)
    # - Proper weight distribution (live ‚Üí gutted ‚Üí fillet)
    # - Marks assignments as inactive
```

**Sample Harvest Data:**
```
Batch: FI-2023-002
Date:  2025-10-17
Lots:  5 (one per grade)
  - SUPERIOR: 10% (15% above avg weight)
  - GRADE_A:  40% (5% above avg weight)  
  - GRADE_B:  35% (average weight)
  - GRADE_C:  12% (15% below avg weight)
  - REJECT:   3%  (40% below avg weight)
```

**Conclusion:** ‚úÖ **No backfill needed** - harvest logic is fully integrated into event engine

---

### **2. Feeding Summaries** ‚úÖ AUTO-GENERATED VIA SIGNALS

```
Status: ‚úÖ WORKING AS DESIGNED (via django signals)
```

**Evidence:**
```
Feeding Events:              691,920 events
Batch Feeding Summaries:     14 summaries
Container Feeding Summaries: 138 summaries
```

**How It Works:**

#### **Signal-Based Auto-Generation**
```python
# Location: apps/inventory/signals.py

@receiver(post_save, sender=FeedingEvent)
def recalculate_fcr_on_feeding_event(sender, instance, created, **kwargs):
    """
    Automatically recalculate FCR when a feeding event is created.
    Uses 30-day rolling window to provide continuous FCR updates.
    """
    # 1. Calculate container-level summary
    container_summary = FCRCalculationService.create_container_feeding_summary(
        assignment, start_date, end_date  # Last 30 days
    )
    
    # 2. Aggregate to batch-level summary
    batch_summary = FCRCalculationService.aggregate_container_fcr_to_batch(
        batch, start_date, end_date
    )
```

**What's Generated:**
```
Period: 2025-09-22 to 2025-10-22 (30-day rolling window)

Example Batch Summaries:
- FI-2024-001: 816,972.9kg feed, FCR: 2.323, Confidence: HIGH
- FI-2024-002: 390,220.5kg feed, FCR: 1.800, Confidence: HIGH
- SCO-2024-001: 809,251.5kg feed, FCR: 2.323, Confidence: HIGH

Note: All summaries cover the SAME 30-day period (by design)
```

**Why Only 14 Summaries for 54 Batches?**

The signals use a **30-day rolling window** strategy:
1. **Active batches only:** Only batches with feeding events in the last 30 days get summaries
2. **Recent data:** Older batches (completed/harvested) won't have recent feeding
3. **By design:** This is intentional - summaries represent "current" state

**Coverage Analysis:**
```python
54 total batches:
  - 44 Adult (many harvested, no recent feeding)
  - 10 in earlier stages (actively feeding)
  
14 batch summaries = ~14 batches with feeding in last 30 days ‚úì
138 container summaries = ~14 batches √ó 10 containers each ‚úì
```

**Conclusion:** ‚úÖ **No backfill needed** - signals generate summaries automatically

---

## üîç **Historical Context: Why Backfilling Was Needed**

### **Transfer Workflows** (Already Backfilled)

```
Script: scripts/data_generation/backfill_transfer_workflows.py
Status: ‚úÖ COMPLETED
```

**Why it was needed:**
- Transfer workflow feature was added AFTER test data generation
- Needed to create workflows for existing stage transitions
- One-time operation to convert historical assignments into workflows

**What it did:**
```
Created:
- 242 BatchTransferWorkflow records
- 2,402 TransferAction records
- Linked to existing BatchContainerAssignment data
```

**Status:** ‚úÖ Now integrated into test scripts (no longer needs backfill)

---

## üìã **What About Finance Harvest Facts?**

### **Current Status:** ‚ùå NOT GENERATED

```python
# Check:
from apps.finance.models import FactHarvest
FactHarvest.objects.count()  # Returns: 0
```

**Why Empty:**
- Finance harvest facts feature developed AFTER test scripts
- Requires mapping harvest events ‚Üí finance dimensions
- Not yet integrated into event engine

**What's Needed:**
```python
# Location: Add to 03_event_engine_core.py::harvest_batch()

def harvest_batch(self):
    # ... existing harvest logic ...
    
    # NEW: Generate finance facts
    from apps.finance.models import FactHarvest, DimCompany, DimSite
    
    for event in harvest_events:
        for lot in event.lots.all():
            # Map to finance dimensions
            company = DimCompany.objects.get(...)
            site = DimSite.objects.get(...)
            
            FactHarvest.objects.create(
                event_date=event.event_date,
                quantity_kg=lot.live_weight_kg,
                unit_count=lot.unit_count,
                dim_batch_id=event.batch.id,
                dim_company=company,
                dim_site=site,
                event=event,
                lot=lot,
                product_grade=lot.product_grade
            )
```

**Recommendation:** üîß **Add to harvest_batch() method** (simple addition)

---

## ‚úÖ **Recommendations**

### **1. Harvest Events**
```
Status: ‚úÖ WORKING - No action needed
```

### **2. Feeding Summaries**
```
Status: ‚úÖ WORKING - No action needed

Note: Sparse coverage is intentional (30-day rolling window)
If you want historical summaries, you can:
  a) Keep current approach (recent data only)
  b) Generate summaries for full lifecycle via API action
```

**Option B - Generate Full Lifecycle Summaries:**
```bash
# Via API (for each batch):
POST /api/v1/inventory/batch-feeding-summaries/generate/
{
  "batch": <batch_id>,
  "period_start": "2024-01-01",
  "period_end": "2024-12-31"
}

# Or via management command (if you create one):
python manage.py generate_feeding_summaries --all-batches --full-lifecycle
```

### **3. Finance Harvest Facts** üîß NEEDS IMPLEMENTATION
```
Priority: MEDIUM
Effort:   1-2 hours
Impact:   Enables finance reporting validation

Action: Add FactHarvest generation to harvest_batch() method
Location: scripts/data_generation/03_event_engine_core.py
```

**Implementation Template:**
```python
# Add at end of harvest_batch() method (after line 688):

def _generate_finance_facts(self, harvest_event):
    """Generate finance fact table entries from harvest event."""
    from apps.finance.models import FactHarvest, DimCompany, DimSite
    
    # Get or create company/site dimensions
    # (You'll need to map geography ‚Üí company/site)
    try:
        # Simplified mapping - adjust based on your data model
        company = DimCompany.objects.get(
            geography=self.geo,
            subsidiary='FARMING'  # or determine from batch/area
        )
        
        # Map to site (freshwater station or sea area)
        if harvest_event.assignment.container.hall:
            site = DimSite.objects.get(
                source_model='STATION',
                source_pk=harvest_event.assignment.container.hall.freshwater_station.id
            )
        else:
            site = DimSite.objects.get(
                source_model='AREA',
                source_pk=harvest_event.assignment.container.area.id
            )
        
        # Create fact record for each lot
        for lot in harvest_event.lots.all():
            FactHarvest.objects.create(
                event_date=harvest_event.event_date,
                quantity_kg=lot.live_weight_kg,
                unit_count=lot.unit_count,
                dim_batch_id=harvest_event.batch.id,
                dim_company=company,
                dim_site=site,
                event=harvest_event,
                lot=lot,
                product_grade=lot.product_grade
            )
        
        print(f"  ‚úì Generated {harvest_event.lots.count()} finance facts")
        
    except Exception as e:
        print(f"  ‚ö† Finance fact generation failed: {e}")
        # Don't block harvest if finance fails
```

---

## üéØ **Summary**

### **Current State:**

| Feature | Status | Backfill Needed? | Action Required |
|---------|--------|------------------|-----------------|
| **Harvest Events** | ‚úÖ Working | ‚ùå No | None - fully integrated |
| **Harvest Lots** | ‚úÖ Working | ‚ùå No | None - fully integrated |
| **Feeding Summaries (Batch)** | ‚úÖ Working | ‚ùå No | None - signals handle it |
| **Feeding Summaries (Container)** | ‚úÖ Working | ‚ùå No | None - signals handle it |
| **Transfer Workflows** | ‚úÖ Working | ‚úÖ Yes (done) | None - already backfilled |
| **Finance Harvest Facts** | ‚ùå Empty | ‚ö†Ô∏è TBD | Add to harvest_batch() |

### **For Scenarios:**

Based on your comment about scenarios being "nice to have" for sea area transitions:

**Recommendation:** üîß **Add lightweight scenario generation**
```python
# Location: End of harvest_batch() or new method
# When:     Batch transitions to Adult stage (Post-Smolt ‚Üí Adult)

def create_sea_transition_scenario(self, batch, transition_date):
    """
    Create a simple scenario when batch moves to sea.
    Uses current batch data as starting point.
    """
    from apps.scenario.models import (
        Scenario, TGCModel, FCRModel, MortalityModel,
        TemperatureProfile
    )
    
    # Create scenario "From Batch"
    scenario = Scenario.objects.create(
        name=f"Sea Growth Forecast - {batch.batch_number}",
        start_date=transition_date,
        duration_days=450,  # Adult stage duration
        initial_count=batch.current_population,
        initial_weight=batch.current_avg_weight,
        batch=batch,
        tgc_model=TGCModel.objects.filter(
            location__icontains=self.geography_name
        ).first(),
        fcr_model=FCRModel.objects.first(),
        mortality_model=MortalityModel.objects.first(),
        created_by=self.user
    )
    
    print(f"  ‚úì Created scenario: {scenario.name}")
    return scenario
```

This would give you realistic "From Batch" scenarios at the most critical decision point (sea transfer).

---

## üìä **Validation Queries**

### **Check Harvest Integration:**
```sql
-- Harvest events vs batches
SELECT 
    ls.name as stage,
    COUNT(DISTINCT b.id) as total_batches,
    COUNT(DISTINCT he.batch_id) as batches_with_harvest,
    COUNT(he.id) as harvest_events
FROM batch_batch b
LEFT JOIN batch_lifecyclestage ls ON b.lifecycle_stage_id = ls.id
LEFT JOIN harvest_harvestevent he ON he.batch_id = b.id
GROUP BY ls.name
ORDER BY ls.order;

-- Expected result:
-- Adult: 44 batches, ~38 with harvest, ~380 events (multiple containers)
```

### **Check Feeding Summary Coverage:**
```sql
-- Summaries vs active batches
SELECT 
    b.batch_number,
    COUNT(DISTINCT fe.id) as feeding_events,
    COUNT(DISTINCT bfs.id) as batch_summaries,
    COUNT(DISTINCT cfs.id) as container_summaries
FROM batch_batch b
LEFT JOIN inventory_feedingevent fe ON fe.batch_id = b.id
LEFT JOIN inventory_batchfeedingsummary bfs ON bfs.batch_id = b.id
LEFT JOIN batch_batchcontainerassignment bca ON bca.batch_id = b.id
LEFT JOIN inventory_containerfeedingsummary cfs ON cfs.container_assignment_id = bca.id
WHERE b.lifecycle_stage_id IN (
    SELECT id FROM batch_lifecyclestage 
    WHERE name IN ('Fry', 'Parr', 'Smolt', 'Post-Smolt', 'Adult')
)
GROUP BY b.batch_number
ORDER BY b.batch_number;

-- Shows which batches have summaries (should be recent/active ones)
```

---

## üîó **Related Documents**

- **Full Coverage Analysis:** `DATABASE_TABLE_COVERAGE_ANALYSIS.md`
- **Empty Tables Reference:** `EMPTY_TABLES_QUICK_REFERENCE.md`
- **Test Data Guide:** `test_data_generation_guide.md`
- **Backfill Script:** `scripts/data_generation/backfill_transfer_workflows.py`

---

**End of Analysis**









