# Phase 2 Complete - ActualDailyAssignmentState Hypertable

**Issue**: #112  
**Branch**: `feature/batch-growth-assimilation-112`  
**Completed**: November 14, 2025

---

## Summary

Phase 2 successfully created the foundation for storing daily computed states with the `ActualDailyAssignmentState` model. Following the TimescaleDB testing strategy, the model works as a regular PostgreSQL table in dev/test environments with separate production scripts for TimescaleDB configuration.

---

## Deliverables

### 1. ActualDailyAssignmentState Model
**File**: `apps/batch/models/actual_daily_state.py`

Core time-series model for storing daily computed states:

| Field Category | Fields | Purpose |
|----------------|--------|---------|
| **Relationships** | assignment, batch, container, lifecycle_stage | Links to existing models |
| **Time Dimension** | date (partition key), day_number | Temporal indexing |
| **Computed Metrics** | avg_weight_g, population, biomass_kg | Daily state values |
| **Environmental** | temp_c, mortality_count, feed_kg, observed_fcr | Operational inputs |
| **Provenance** | anchor_type, sources (JSON), confidence_scores (JSON) | Data transparency |
| **Metadata** | last_computed_at | Computation tracking |

**Key Features**:
- Unique constraint on (assignment, date) - one state per assignment per day
- 4 indexes for efficient querying (assignment+date, batch+date, date, anchor_type)
- JSON fields for flexible provenance tracking
- Works as regular PostgreSQL table or TimescaleDB hypertable

### 2. Database Migrations

**Migration batch/0033**: `create_actual_daily_state_model.py`
- Creates ActualDailyAssignmentState table
- Adds unique constraint and indexes
- Generated by Django makemigrations

**Migration batch/0034**: `setup_timescaledb_hypertable.py`
- Placeholder migration (skips TimescaleDB setup in dev)
- References production setup script
- Follows TimescaleDB testing strategy

**Migration environmental/0014**: `create_daily_temp_cagg.py`
- Placeholder migration (skips CAGG setup in dev)
- References production setup script
- Avoids dependency on hypertable configuration

### 3. Production Setup Scripts

**File**: `scripts/timescaledb/setup_daily_state_hypertable.sql`

Production script to configure TimescaleDB hypertable:
1. Update primary key to (id, date)
2. Create hypertable with 14-day chunks
3. Enable compression (segment by assignment_id, order by date DESC)
4. Add compression policy (compress after 30 days)

**File**: `scripts/timescaledb/setup_temperature_cagg.sql`

Production script to create temperature continuous aggregate:
1. Verify environmental_environmentalreading is a hypertable
2. Create env_daily_temp_by_container materialized view
3. Add refresh policy (hourly, last 7 days)

**Usage**:
```bash
# In production PostgreSQL with TimescaleDB
psql -U postgres -d aquamind -f scripts/timescaledb/setup_daily_state_hypertable.sql
psql -U postgres -d aquamind -f scripts/timescaledb/setup_temperature_cagg.sql
```

---

## Test Results

### Schema Validation Tests
- **File**: `apps/batch/tests/test_phase2_schema_only.py`
- **Tests**: 8/8 passing
- **Coverage**:
  - Model existence and table name
  - All required fields present
  - Anchor type choices
  - JSON field configuration
  - Nullable fields
  - Unique constraint validation
  - Index definitions
  - Database table creation

### Full Test Suite
- **PostgreSQL**: 1231/1231 tests passing (20 skipped)
- **SQLite (CI)**: 1231/1231 tests passing (62 skipped)
- **Result**: ✅ 100% pass rate on both databases

---

## TimescaleDB Strategy

Per `aquamind/docs/quality_assurance/timescaledb_testing_strategy.md`:

**Development/Testing**:
- ActualDailyAssignmentState works as regular PostgreSQL table
- No TimescaleDB dependencies in migrations
- All tests pass without TimescaleDB extension

**Production**:
- Run manual setup scripts to enable TimescaleDB features
- Hypertable partitioning for efficient time-series storage
- Compression to reduce storage footprint
- CAGGs for fast temperature aggregations

**Benefits**:
- ✅ Database-agnostic migrations
- ✅ No transaction aborts during development
- ✅ CI/CD pipeline compatibility
- ✅ Production-grade TimescaleDB features when needed

---

## Data Model Details

### Table Structure

```sql
CREATE TABLE batch_actualdailyassignmentstate (
    id BIGSERIAL PRIMARY KEY,
    assignment_id BIGINT NOT NULL REFERENCES batch_batchcontainerassignment(id),
    batch_id BIGINT NOT NULL REFERENCES batch_batch(id),
    container_id BIGINT NOT NULL REFERENCES infrastructure_container(id),
    lifecycle_stage_id BIGINT NOT NULL REFERENCES batch_lifecyclestage(id),
    date DATE NOT NULL,
    day_number INTEGER NOT NULL,
    avg_weight_g NUMERIC(10,2) NOT NULL,
    population INTEGER NOT NULL,
    biomass_kg NUMERIC(12,2) NOT NULL,
    temp_c NUMERIC(5,2),
    mortality_count INTEGER NOT NULL DEFAULT 0,
    feed_kg NUMERIC(10,2) NOT NULL DEFAULT 0,
    observed_fcr NUMERIC(6,3),
    anchor_type VARCHAR(20),
    sources JSONB NOT NULL DEFAULT '{}',
    confidence_scores JSONB NOT NULL DEFAULT '{}',
    last_computed_at TIMESTAMP NOT NULL,
    CONSTRAINT unique_assignment_date UNIQUE (assignment_id, date)
);
```

### Indexes

| Index Name | Fields | Purpose |
|------------|--------|---------|
| idx_assignment_date | (assignment, date) | Primary query pattern |
| idx_batch_date | (batch, date) | Batch-level aggregation |
| idx_date | (date) | Time-based queries |
| idx_anchor_type | (anchor_type) | Anchor analysis |

---

## Storage Considerations

### Development
- Regular PostgreSQL table
- Standard B-tree indexes
- Estimated size: ~1KB per row
- For 33 batches × 456 assignments × 900 days ≈ 13.5M rows ≈ 13.5 GB

### Production (with TimescaleDB)
- Hypertable with 14-day chunks
- Compression after 30 days (expect 70-90% reduction)
- Estimated compressed size: ~1.5-4 GB
- Query performance: Sub-second for most queries

---

## Next Steps: Phase 3

Phase 3 will implement the core computation engine:
1. Anchor detection logic (growth samples, transfers, vaccinations)
2. TGC-based growth calculations between anchors
3. Temperature/mortality/feed data retrieval with fallbacks
4. Population and biomass calculations
5. Provenance tracking (sources and confidence scores)
6. Stage transitions based on weight thresholds
7. Integration hooks for Production Planner triggers

**Ready to proceed**: Model is in place, migrations applied, tests pass.

---

## Git History

| Commit | Description |
|--------|-------------|
| `062545b` | feat(batch-growth): Phase 2 - ActualDailyAssignmentState model and TimescaleDB setup |

---

## Checklist

- [x] Model created with all required fields
- [x] Migrations created and applied
- [x] TimescaleDB setup scripts provided for production
- [x] Tests written and passing (8/8 schema tests)
- [x] PostgreSQL compatibility verified (1231/1231 tests pass)
- [x] SQLite compatibility verified (1231/1231 tests pass)
- [x] Database-agnostic approach confirmed
- [x] Documentation updated
- [x] Git commits clean and descriptive
- [x] Implementation plan updated

