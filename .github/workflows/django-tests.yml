name: AquaMind CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Lint with flake8
      run: |
        pip install flake8
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Audit API router basenames
      run: |
        # Ensure all DRF router registrations use explicit, unique kebab-case basenames.
        # The script exits with a non-zero status code if any violations are found,
        # thereby failing the workflow and preventing a merge that would break
        # our API consistency guarantees.
        python audit_basenames.py
    
    - name: Run migrations
      run: |
        python manage.py migrate --settings=aquamind.settings_ci
    
    - name: Run tests
      run: |
        # Only run tests for implemented features
        # As we complete more features from the implementation plan, we'll add their tests here
        python manage.py test --settings=aquamind.settings_ci --noinput

    # ------------------------------------------------------------------
    # OpenAPI Spec Completeness ‚Äì validate schema & post-processing hooks
    # ------------------------------------------------------------------
    - name: Run OpenAPI spec completeness tests
      run: |
        # Focused suite that validates the generated OpenAPI schema
        # (presence of standard responses, hook configuration, integer bounds, etc.)
        python manage.py test apps.infrastructure.tests.test_openapi_spec \
          --settings=aquamind.settings_ci --noinput
    
    - name: Generate test coverage report
      run: |
        pip install coverage
        # Only generate coverage for implemented features
        coverage run --source='.' manage.py test --settings=aquamind.settings_ci --noinput
        # Increasing coverage requirement as we implement more features
        coverage report --fail-under=40
      # Environment variables for PostgreSQL removed as CI now uses SQLite

    # ------------------------------------------------------------------
    # Cross-repo API Contract Synchronisation
    # ------------------------------------------------------------------
    - name: Generate OpenAPI spec
      run: |
        # drf-spectacular generates unified OpenAPI 3.1 schema
        python manage.py spectacular --file api/openapi.yaml --settings=aquamind.settings_ci

    # ------------------------------------------------------------------
    # Contract validation ‚Äì ensure implementation matches the OpenAPI spec
    # ------------------------------------------------------------------
    - name: Validate API contract with Schemathesis
      run: |
        # ------------------------------------------------------------------
        # Prepare database for the live dev-server that Schemathesis will hit
        # (The earlier migration step ran against a *different* SQLite file /
        # in-memory DB used by the test runner. We need to migrate the runtime
        # DB as well to avoid "no such table: auth_user" errors.)
        # ------------------------------------------------------------------
        # Apply migrations (no need to capture output)
        python manage.py migrate --settings=aquamind.settings_ci --noinput

        # ------------------------------------------------------------------
        # Obtain / create the CI JWT tokens using a dedicated management command
        # ------------------------------------------------------------------
        echo "üîë Generating CI JWT tokens..."

        # Generate JWT tokens with debug output to see what's happening
        TOKENS_JSON=$(python manage.py get_ci_token --settings=aquamind.settings_ci --debug)

        # Check if token generation succeeded
        if [ $? -ne 0 ]; then
          echo "‚ùå JWT token generation command failed"
          exit 1
        fi

        # Check if tokens are empty
        if [ -z "$TOKENS_JSON" ]; then
          echo "‚ùå Failed to obtain CI JWT tokens - empty response"
          exit 1
        fi

        # Parse JSON tokens and extract access/refresh tokens
        ACCESS_TOKEN=$(echo "$TOKENS_JSON" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('access', ''))")
        REFRESH_TOKEN=$(echo "$TOKENS_JSON" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('refresh', ''))")

        # Validate tokens
        if [ -z "$ACCESS_TOKEN" ] || [ -z "$REFRESH_TOKEN" ]; then
          echo "‚ùå Failed to parse JWT tokens from response"
          echo "Response: $TOKENS_JSON"
          exit 1
        fi

        # Debug: Print token info (without exposing the actual tokens)
        echo "ACCESS_TOKEN length = ${#ACCESS_TOKEN}"
        echo "REFRESH_TOKEN length = ${#REFRESH_TOKEN}"
        echo "‚úÖ CI JWT tokens ready"

        # Mask the tokens for security
        echo "::add-mask::$ACCESS_TOKEN"
        echo "::add-mask::$REFRESH_TOKEN"

        # ------------------------------------------------------------------
        # Export tokens for Schemathesis hooks - ensure they're available in next step
        # ------------------------------------------------------------------
        echo "SCHEMATHESIS_ACCESS_TOKEN=$ACCESS_TOKEN" >> $GITHUB_ENV
        echo "SCHEMATHESIS_REFRESH_TOKEN=$REFRESH_TOKEN" >> $GITHUB_ENV
        echo "üîß JWT tokens exported to environment"

    - name: Run Schemathesis contract tests
      run: |
        # ------------------------------------------------------------------
        # Start Django dev server in background
        # ------------------------------------------------------------------
        python manage.py runserver 0.0.0.0:8000 --settings=aquamind.settings_ci &
        SERVER_PID=$!

        # Wait for server to be ready (max 60 s)
        ATTEMPTS=0
        until curl -s http://127.0.0.1:8000/ > /dev/null; do
          ATTEMPTS=$((ATTEMPTS+1))
          if [ $ATTEMPTS -gt 30 ]; then
            echo "Server did not start in time"; kill $SERVER_PID; exit 1
          fi
          echo "‚è≥ Waiting for server to start‚Ä¶"
          sleep 2
        done
        echo "‚úÖ Django server is up ‚Äì running Schemathesis"

        # ------------------------------------------------------------------
        # Install schemathesis and run contract tests
        # ------------------------------------------------------------------
        pip install --quiet schemathesis

        # Set up Schemathesis environment and hooks
        echo "üîå Setting up Schemathesis hooks..."
        export SCHEMATHESIS_HOOKS="aquamind.utils.schemathesis_hooks"

        # Verify environment variables are set correctly
        echo "SCHEMATHESIS_HOOKS = $SCHEMATHESIS_HOOKS"
        echo "SCHEMATHESIS_AUTH_TOKEN length = ${#SCHEMATHESIS_AUTH_TOKEN}"

        if [ -z "$SCHEMATHESIS_AUTH_TOKEN" ]; then
          echo "‚ùå SCHEMATHESIS_AUTH_TOKEN is not set!"
          exit 1
        fi

        echo "‚úÖ Schemathesis environment ready"

        # Run Schemathesis contract tests
        schemathesis run \
          --base-url=http://127.0.0.1:8000 \
          --checks all \
          --hypothesis-max-examples=10 \
          --hypothesis-suppress-health-check=filter_too_much,data_too_large \
          --hypothesis-derandomize \
          --show-errors-tracebacks \
          api/openapi.yaml \
          > schemathesis-output.txt 2>&1

        STATUS=$?

        # Show quick preview of the log for easier debugging
        echo "---------------- First 100 lines of Schemathesis output ----------------"
        head -n 100 schemathesis-output.txt || true
        echo "----------------  Last 100 lines of Schemathesis output ----------------"
        tail -n 100 schemathesis-output.txt || true

        # Emit summary message if failures detected
        if [ $STATUS -ne 0 ]; then
          echo "‚ùå Schemathesis detected contract test failures"
        fi

        echo "‚èπ  Stopping Django server"
        kill $SERVER_PID
        exit $STATUS

    - name: Upload Schemathesis output artifact (contract-test-log)
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: schemathesis-output
        path: schemathesis-output.txt

    - name: Upload OpenAPI spec artifact (api-spec)
      # This artifact is consumed by the front-end workflow that regenerates
      # the TypeScript client, ensuring both repos stay in sync.
      uses: actions/upload-artifact@v4
      with:
        name: api-spec
        path: api/openapi.yaml
        if-no-files-found: error

  deploy-staging:
    needs: test
    if: github.ref == 'refs/heads/develop'
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment"
        # Add actual deployment commands here
        # This is a placeholder for your deployment process
      # Will add environment variables when actual deployment is implemented
      # env:
      #   DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
  
  deploy-production:
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Deploy to production
      run: |
        echo "Deploying to production environment"
        # Add actual deployment commands here
        # This is a placeholder for your deployment process
      # Will add environment variables when actual deployment is implemented
      # env:
      #   DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
